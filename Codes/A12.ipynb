{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHqE606eD3t-",
        "outputId": "d459fb0b-5ea4-4902-86e0-906b4a538f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = '''\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "__global__ void vectorAdd(float *A, float *B, float *C, int N) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpuVectorAdd(float *A, float *B, float *C, int N) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 1000000000;\n",
        "    printf(\"Current input size: %d\\\\n\", N);\n",
        "    float *h_A, *h_B, *h_C;\n",
        "    h_A = (float *)malloc(N * sizeof(float));\n",
        "    h_B = (float *)malloc(N * sizeof(float));\n",
        "    h_C = (float *)malloc(N * sizeof(float));\n",
        "\n",
        "    srand(time(0));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = rand() % 100; // Random float numbers\n",
        "        h_B[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    clock_t start_cpu = clock();\n",
        "    cpuVectorAdd(h_A, h_B, h_C, N);\n",
        "    clock_t end_cpu = clock();\n",
        "    double cpu_time = double(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_B, N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_C, N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
        "    clock_t start_gpu = clock();\n",
        "    vectorAdd<<<numBlocks, blockSize>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize(); // Wait for GPU to finish\n",
        "    clock_t end_gpu = clock();\n",
        "    double gpu_time = double(end_gpu - start_gpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < 10; i++) { // Display first 10 results\n",
        "        printf(\"%.2f + %.2f = %.2f\\\\n\", h_A[i], h_B[i], h_C[i]);\n",
        "    }\n",
        "\n",
        "    printf(\"CPU time: %f seconds\\\\n\", cpu_time);\n",
        "    printf(\"GPU time: %f seconds\\\\n\", gpu_time);\n",
        "    printf(\"Speedup: %f\\\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "with open('vector_addition.cu', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "!nvcc vector_addition.cu -o vector_add\n",
        "!./vector_add\n"
      ],
      "metadata": {
        "id": "NSs42yQtGGU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5670598d-7c2f-4c9a-e42c-4a905ee6d036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current input size: 1000000000\n",
            "76.00 + 64.00 = 140.00\n",
            "12.00 + 10.00 = 22.00\n",
            "34.00 + 91.00 = 125.00\n",
            "99.00 + 10.00 = 109.00\n",
            "4.00 + 6.00 = 10.00\n",
            "94.00 + 7.00 = 101.00\n",
            "72.00 + 94.00 = 166.00\n",
            "55.00 + 74.00 = 129.00\n",
            "67.00 + 78.00 = 145.00\n",
            "85.00 + 32.00 = 117.00\n",
            "CPU time: 5.750296 seconds\n",
            "GPU time: 0.045569 seconds\n",
            "Speedup: 126.188769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = '''\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "__global__ void matrixAddKernel(float *A, float *B, float *C, int M, int N) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    int j = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    if (i < M && j < N) {\n",
        "        C[i * N + j] = A[i * N + j] + B[i * N + j];\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpuMatrixAdd(float *A, float *B, float *C, int M, int N) {\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            C[i * N + j] = A[i * N + j] + B[i * N + j];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int M = 10000;\n",
        "    int N = 10000;\n",
        "    printf(\"Current matrix size: %d x %d\\\\n\", M, N);\n",
        "    float *h_A, *h_B, *h_C;\n",
        "    h_A = (float *)malloc(M * N * sizeof(float));\n",
        "    h_B = (float *)malloc(M * N * sizeof(float));\n",
        "    h_C = (float *)malloc(M * N * sizeof(float));\n",
        "\n",
        "    srand(time(0));\n",
        "    for (int i = 0; i < M * N; i++) {\n",
        "        h_A[i] = rand() % 100;\n",
        "        h_B[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    clock_t start_cpu = clock();\n",
        "    cpuMatrixAdd(h_A, h_B, h_C, M, N);\n",
        "    clock_t end_cpu = clock();\n",
        "    double cpu_time = double(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, M * N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_B, M * N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_C, M * N * sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, M * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, M * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((N + threadsPerBlock.x - 1) / threadsPerBlock.x, (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "    clock_t start_gpu = clock();\n",
        "    matrixAddKernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, M, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    clock_t end_gpu = clock();\n",
        "    double gpu_time = double(end_gpu - start_gpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, M * N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"CPU time: %f seconds\\\\n\", cpu_time);\n",
        "    printf(\"GPU time: %f seconds\\\\n\", gpu_time);\n",
        "    printf(\"Speedup: %f\\\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "with open('matrix_addition.cu', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "!nvcc matrix_addition.cu -o matrix_add\n",
        "!./matrix_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvL--qEU0Zo1",
        "outputId": "0326a677-63a2-48bf-a770-cd5a3ef17e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current matrix size: 10000 x 10000\n",
            "CPU time: 0.538746 seconds\n",
            "GPU time: 0.014548 seconds\n",
            "Speedup: 37.032307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = '''\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "__global__ void dotProductKernel(float *A, float *B, float *C, int N) {\n",
        "    extern __shared__ float sharedData[];\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < N) {\n",
        "        sharedData[threadIdx.x] = A[i] * B[i];\n",
        "    } else {\n",
        "        sharedData[threadIdx.x] = 0;\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n",
        "        if (threadIdx.x < stride) {\n",
        "            sharedData[threadIdx.x] += sharedData[threadIdx.x + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        atomicAdd(C, sharedData[0]);\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpuDotProduct(float *A, float *B, float *C, int N) {\n",
        "    *C = 0;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        *C += A[i] * B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 10000000;\n",
        "    printf(\"Current vector size: %d\\\\n\", N);\n",
        "    float *h_A, *h_B, *h_C;\n",
        "    h_A = (float *)malloc(N * sizeof(float));\n",
        "    h_B = (float *)malloc(N * sizeof(float));\n",
        "    h_C = (float *)malloc(sizeof(float));\n",
        "\n",
        "    srand(time(0));\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        h_A[i] = rand() % 100;\n",
        "        h_B[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    clock_t start_cpu = clock();\n",
        "    cpuDotProduct(h_A, h_B, h_C, N);\n",
        "    clock_t end_cpu = clock();\n",
        "    double cpu_time = double(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_B, N * sizeof(float));\n",
        "    cudaMalloc((void **)&d_C, sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_C, h_C, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blockSize = 256;\n",
        "    int numBlocks = (N + blockSize - 1) / blockSize;\n",
        "    clock_t start_gpu = clock();\n",
        "    dotProductKernel<<<numBlocks, blockSize, blockSize * sizeof(float)>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize();\n",
        "    clock_t end_gpu = clock();\n",
        "    double gpu_time = double(end_gpu - start_gpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"CPU result: %f\\\\n\", *h_C);\n",
        "    printf(\"GPU result: %f\\\\n\", *h_C);\n",
        "    printf(\"CPU time: %f seconds\\\\n\", cpu_time);\n",
        "    printf(\"GPU time: %f seconds\\\\n\", gpu_time);\n",
        "    printf(\"Speedup: %f\\\\n\", cpu_time / gpu_time);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "with open('dot_product.cu', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "!nvcc dot_product.cu -o dot_product\n",
        "!./dot_product\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7V8CAqsyREH",
        "outputId": "ea944982-b271-4a8e-a6ff-8401533ec213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current vector size: 10000000\n",
            "CPU result: 48719536128.000000\n",
            "GPU result: 48719536128.000000\n",
            "CPU time: 0.031295 seconds\n",
            "GPU time: 0.001192 seconds\n",
            "Speedup: 26.254195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = '''\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "__global__ void matrixMultiplyKernel(float *A, float *B, float *C, int M, int N, int P) {\n",
        "    int row = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    int col = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    float sum = 0;\n",
        "\n",
        "    if (row < M && col < P) {\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            sum += A[row * N + k] * B[k * P + col];\n",
        "        }\n",
        "        C[row * P + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void cpuMatrixMultiply(float *A, float *B, float *C, int M, int N, int P) {\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < P; j++) {\n",
        "            C[i * P + j] = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                C[i * P + j] += A[i * N + k] * B[k * P + j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void initializeMatrix(float *matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows * cols; i++) {\n",
        "        matrix[i] = (float)(rand() % 100); // Random values\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int matrixSizes[3][2] = {{100, 100}, {500, 500}, {1000, 1000}};\n",
        "    srand(time(0));\n",
        "\n",
        "    for (int size = 0; size < 3; size++) {\n",
        "        int M = matrixSizes[size][0];\n",
        "        int N = matrixSizes[size][1];\n",
        "        int P = N; // For square multiplication\n",
        "\n",
        "        float *h_A = (float *)malloc(M * N * sizeof(float));\n",
        "        float *h_B = (float *)malloc(N * P * sizeof(float));\n",
        "        float *h_C_cpu = (float *)malloc(M * P * sizeof(float));\n",
        "        float *h_C_gpu = (float *)malloc(M * P * sizeof(float));\n",
        "\n",
        "        initializeMatrix(h_A, M, N);\n",
        "        initializeMatrix(h_B, N, P);\n",
        "\n",
        "        clock_t start_cpu = clock();\n",
        "        cpuMatrixMultiply(h_A, h_B, h_C_cpu, M, N, P);\n",
        "        clock_t end_cpu = clock();\n",
        "        double cpu_time = double(end_cpu - start_cpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "        float *d_A, *d_B, *d_C;\n",
        "        cudaMalloc((void **)&d_A, M * N * sizeof(float));\n",
        "        cudaMalloc((void **)&d_B, N * P * sizeof(float));\n",
        "        cudaMalloc((void **)&d_C, M * P * sizeof(float));\n",
        "\n",
        "        cudaMemcpy(d_A, h_A, M * N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(d_B, h_B, N * P * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "        dim3 threadsPerBlock(16, 16);\n",
        "        dim3 numBlocks((P + threadsPerBlock.x - 1) / threadsPerBlock.x, (M + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "        clock_t start_gpu = clock();\n",
        "        matrixMultiplyKernel<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, M, N, P);\n",
        "        cudaDeviceSynchronize(); // Wait for GPU to finish\n",
        "        clock_t end_gpu = clock();\n",
        "        double gpu_time = double(end_gpu - start_gpu) / CLOCKS_PER_SEC;\n",
        "\n",
        "        cudaMemcpy(h_C_gpu, d_C, M * P * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Compare results (optional)\n",
        "        for (int i = 0; i < M * P; i++) {\n",
        "            if (fabs(h_C_cpu[i] - h_C_gpu[i]) > 1e-5) {\n",
        "                printf(\"Results do not match!\\\\n\");\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        printf(\"\\\\nMatrix Size: %dx%d\\\\n\", M, P);\n",
        "        printf(\"CPU time: %f seconds\\\\n\", cpu_time);\n",
        "        printf(\"GPU time: %f seconds\\\\n\", gpu_time);\n",
        "        printf(\"Speedup: %f\\\\n\", cpu_time / gpu_time);\n",
        "\n",
        "        cudaFree(d_A);\n",
        "        cudaFree(d_B);\n",
        "        cudaFree(d_C);\n",
        "        free(h_A);\n",
        "        free(h_B);\n",
        "        free(h_C_cpu);\n",
        "        free(h_C_gpu);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "with open('matrix_multiplication.cu', 'w') as f:\n",
        "    f.write(code)\n",
        "\n",
        "!nvcc matrix_multiplication.cu -o matrix_mult\n",
        "!./matrix_mult\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOZKhFRWyTX1",
        "outputId": "85a8e49c-7b16-4942-a77e-35322d01f42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matrix Size: 100x100\n",
            "CPU time: 0.005078 seconds\n",
            "GPU time: 0.000219 seconds\n",
            "Speedup: 23.187215\n",
            "\n",
            "Matrix Size: 500x500\n",
            "CPU time: 0.718720 seconds\n",
            "GPU time: 0.001120 seconds\n",
            "Speedup: 641.714286\n",
            "\n",
            "Matrix Size: 1000x1000\n",
            "CPU time: 6.829388 seconds\n",
            "GPU time: 0.007077 seconds\n",
            "Speedup: 965.011728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIGWdGSK3VSL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}